{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from scripts import mapOutputs2D as mout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This example illustrates the effect of increasing time step length on the resulting landscape evolution.**\n",
    "\n",
    "#### Mesh creation\n",
    "\n",
    "In this example, we use the same mesh as the one defined in the `generate_mesh` folder. The initial surface consists of a flat triangulated squared grid (with noise) with 100 km sides and 200 m resolution\n",
    "\n",
    "It defines a flat elevation at 200 m (with noise) and a simple tectonic uplift (with a linear slope ranging to 5 mm/yr). \n",
    "\n",
    "The goSPL input file (`gospl_mesh.npz`) has been copied in the `data` folder. Below we provide the code needed to regenerate it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mesh = False\n",
    "if make_mesh:\n",
    "    \n",
    "    import meshio\n",
    "    import meshplex\n",
    "    import uxarray as uxr\n",
    "    from scripts import umeshFcts as ufcts\n",
    "\n",
    "    dx = 200 # desired resolution\n",
    "    nx = 501 # desired number of nodes along the x-axis\n",
    "    ny = 501 # desired number of nodes along the y-axis\n",
    "\n",
    "    tmin = 0.\n",
    "    tmax = 0.005\n",
    "\n",
    "    xcoords = np.arange(nx)*float(dx) \n",
    "    ycoords = np.arange(ny)*float(dx) \n",
    "    tecx = np.interp(xcoords, [xcoords[0],xcoords[-1]], [tmin,tmax])\n",
    "    tec = np.broadcast_to(tecx, (nx, nx))[:ny,:]\n",
    "\n",
    "\n",
    "    noise = np.random.normal(0, 0.05, tec.shape)\n",
    "    elev = noise+100.\n",
    "\n",
    "    ds = xr.Dataset({\n",
    "        'elev': xr.DataArray(\n",
    "                    data   = elev,\n",
    "                    dims   = ['y','x'],\n",
    "                    coords = {'x': xcoords,'y': ycoords},\n",
    "                    ),\n",
    "        'tec': xr.DataArray(\n",
    "                    data   = tec,\n",
    "                    dims   = ['y','x'],\n",
    "                    coords = {'x': xcoords,'y': ycoords},\n",
    "                    )\n",
    "            }\n",
    "        )\n",
    "    ds['cellwidth'] = (['y','x'],dx*np.ones( (ny, nx)))\n",
    "\n",
    "\n",
    "    output_path = \"slope_tec\" \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    # Build your planar mesh\n",
    "    ufcts.planarMesh(ds,output_path,fvtk='planar.vtk',fumpas=True,voro=True)\n",
    "\n",
    "    # Loading the UGRID file\n",
    "    ufile = output_path+'/base2D.nc'\n",
    "    var_name = 'data'\n",
    "    ugrid = uxr.open_grid(ufile) \n",
    "\n",
    "    # Perform the interpolation (bilinear) \n",
    "    ufcts.inter2UGRID(ds[['elev','tec']],ugrid,output_path,var_name,type='face',latlon=False)\n",
    "    # ufcts.inter2UGRID(ds[['t']],ugrid,output_path,var_name,type='face',latlon=False)\n",
    "\n",
    "    data_file = [output_path+'/'+var_name+'.nc']\n",
    "    # Get the information related to the mesh: primal and dual mesh\n",
    "    primal_mesh = uxr.open_dataset(ufile, *data_file, use_dual=False)\n",
    "    dual_mesh = uxr.open_dataset(ufile, *data_file, use_dual=True)\n",
    "\n",
    "    # Extract nodes and faces information\n",
    "    ucoords = np.empty((dual_mesh.uxgrid.n_node,3))\n",
    "    ucoords[:,0] = dual_mesh.uxgrid.node_x.values\n",
    "    ucoords[:,1] = dual_mesh.uxgrid.node_y.values\n",
    "    ucoords[:,2] = dual_mesh.uxgrid.node_z.values\n",
    "    ufaces = primal_mesh.uxgrid.node_face_connectivity.values\n",
    "\n",
    "    # Get information about your mesh:\n",
    "    print(\"Number of nodes: \",len(ucoords),\" | number of faces \",len(ufaces))\n",
    "    edge_min = np.round(dual_mesh.uxgrid.edge_node_distances.min().values/1000.+0.,2)\n",
    "    edge_max = np.round(dual_mesh.uxgrid.edge_node_distances.max().values/1000.+0.,2)\n",
    "    edge_mean = np.round(dual_mesh.uxgrid.edge_node_distances.mean().values/1000.+0.,2)\n",
    "    print(\"edge range (km): min \",edge_min,\" | max \",edge_max,\" | mean \",edge_mean)\n",
    "\n",
    "    mesh = meshio.read(output_path+'/planar.vtk')\n",
    "    vertex = mesh.points\n",
    "    cells = mesh.cells[1][:][1]\n",
    "    Umesh = meshplex.MeshTri(vertex, cells)\n",
    "    Uarea = Umesh.control_volumes\n",
    "    print('Cell area (km2): ',Uarea.min()*1.e-6,Uarea.max()*1.e-6)\n",
    "\n",
    "    meshname = \"data/gospl_mesh\"\n",
    "    np.savez_compressed(meshname, v=vertex, c=cells, \n",
    "                    z=primal_mesh.elev.data, t=primal_mesh.tec.data\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find a series of goSPL input files:\n",
    "- input-500.yml\n",
    "- input-1.25k.yml\n",
    "- input-2.5k.yml\n",
    "- input-5k.yml\n",
    "\n",
    "These files use the same elevation and forcing conditions, the only difference being the time step used to solve the stream power equation (ranging from 500 yrs to 5,000 years).\n",
    "\n",
    "The surface is exposed to an uniform precipitation regime of 1 m/yr and is uplifted linearly from its fixed western side to the eastern one that experiences an uplift of 5 mm/yr. \n",
    "\n",
    "The value of the bedrock erodibility parameter K is set to 2e-4 in order to reach steady state during the simulated 1.e5 years. The model is purely erosional and therefore marine sedimentation is not considered. In addition, hillslope processes are also turned off, meaning that this example only relies on the implicit parallel flow discharge (using a single flow direction approach) and erosion equations.\n",
    "\n",
    "In both cases the implicit schemas converge for the chosen solver and preconditioner (i.e. Richardson with block Jacobian).\n",
    "\n",
    "\n",
    "## Running the simulations\n",
    "\n",
    "To run the different simulations, you will need to do the following in a terminal:\n",
    "\n",
    "```bash\n",
    "mpirun -np X python3 runModel.py -i input-XX.yml \n",
    "```\n",
    "\n",
    "where X is the number of processors to use (for example 5), and XX is the time step based on the input file name (for example 1k)\n",
    "\n",
    "## Visualising the outputs\n",
    "\n",
    "You can visualise the outputs of your simulations directly in Paraview. Below we also show how this could be extracted as netcdf grids and analysed in Python.\n",
    "\n",
    "\n",
    "To do so, we will be using the `mapOutputs` Python class (available in the `scripts` folder) to first extract the outputs, remap the unstructured variables on a structured mesh. The class is also performing additional calculations on the dataset to extract individual catchments based on flow accumulation and elevation.\n",
    "\n",
    "The interpolated model's variables are then exported as `netCDF` files, and each of them contains the following (if available from the simulation):\n",
    "\n",
    "+ elevation `elevation` (m)\n",
    "+ cumulative erosion/deposition `erodep` (m)\n",
    "+ erosion/deposition rate `erodep_rate` (m/yr)\n",
    "+ water flux discharge (accounting for lakes) `fillDischarge`(m3/yr)\n",
    "+ sediment flux in rivers `sedimentLoad` (m3/yr)\n",
    "+ main basin ids `basinID` (integer)\n",
    "+ rainfall `precipitation` (m/yr)\n",
    "+ tectonic `uplift` (m/yr)\n",
    "+ cumulative flexural isostasy `flex` (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output folder name for the simulation\n",
    "out_path = 'results/'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "    \n",
    "# The step corresponds to the output we want to generate, here we chose 10 as an example\n",
    "stp = 10\n",
    "\n",
    "# Name of each netcdf output file\n",
    "ncout = os.path.join(out_path, \"500yr_stp\")\n",
    "\n",
    "# Initialisation of the class\n",
    "grid500 = mout.mapOutputs(path='./', filename='input-500.yml', step=stp, \n",
    "                       uplift=True, flex=False, model=\"utm\")\n",
    "\n",
    "# Remap the variables on the regular mesh using distance weighting interpolation\n",
    "grid500.buildUTMmesh(res=200., nghb=4, smth=0.5)\n",
    "\n",
    "# Export corresponding regular mesh variables as netCDF file\n",
    "grid500.exportNetCDF(ncfile = ncout+str(stp)+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we extract the grids for the other simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1k simulation\n",
    "ncout = os.path.join(out_path, \"1.25ky_stp\")\n",
    "grid1k = mout.mapOutputs(path='./', filename='input-1.25k.yml', step=stp, \n",
    "                       uplift=True, flex=False, model=\"utm\")\n",
    "grid1k.buildUTMmesh(res=200., nghb=4, smth=0.5)\n",
    "grid1k.exportNetCDF(ncfile = ncout+str(stp)+'.nc')\n",
    "\n",
    "# 2.5k simulation\n",
    "ncout = os.path.join(out_path, \"2.5ky_stp\")\n",
    "grid10k = mout.mapOutputs(path='./', filename='input-2.5k.yml', step=stp, \n",
    "                       uplift=True, flex=False, model=\"utm\")\n",
    "grid10k.buildUTMmesh(res=200., nghb=4, smth=0.5)\n",
    "grid10k.exportNetCDF(ncfile = ncout+str(stp)+'.nc')\n",
    "\n",
    "# 5k simulation\n",
    "ncout = os.path.join(out_path, \"5ky_stp\")\n",
    "grid5k = mout.mapOutputs(path='./', filename='input-5k.yml', step=stp, \n",
    "                       uplift=True, flex=False, model=\"utm\")\n",
    "grid5k.buildUTMmesh(res=200., nghb=4, smth=0.5)\n",
    "grid5k.exportNetCDF(ncfile = ncout+str(stp)+'.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the information for each time step, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputs(finput,ncout,maxstp,res):\n",
    "\n",
    "    grid = mout.mapOutputs(path='./', filename=finput, step=0, \n",
    "                        uplift=True, flex=False, model=\"utm\")\n",
    "    grid.buildUTMmesh(res=res, nghb=4, smth=0.)\n",
    "    grid.exportNetCDF(ncfile = ncout+str(0)+'.nc')\n",
    "    for k in range(0, maxstp+1):\n",
    "        if k>0:\n",
    "            grid.getData(k)\n",
    "        grid.buildUTMmesh(res=res, nghb=4, smth=0.)\n",
    "        grid.exportNetCDF(ncfile = ncout+str(k)+'.nc')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getOutputs('input-500.yml',os.path.join(out_path, \"500yr_stp\"),40,200)\n",
    "\n",
    "getOutputs('input-1.25k.yml',os.path.join(out_path, \"1.25ky_stp\"),40,200)\n",
    "\n",
    "getOutputs('input-2.5k.yml',os.path.join(out_path, \"2.5ky_stp\"),40,200)\n",
    "\n",
    "getOutputs('input-5k.yml',os.path.join(out_path, \"5ky_stp\"),20,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise a specific output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = xr.open_dataset(\"results/500yr_stp40.nc\")\n",
    "sim2 = xr.open_dataset(\"results/1.25ky_stp40.nc\")\n",
    "sim3 = xr.open_dataset(\"results/2.5ky_stp40.nc\")\n",
    "sim4 = xr.open_dataset(\"results/5ky_stp20.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(8,8), sharex=True, sharey=True)\n",
    "sim1.elevation.plot(ax=axs[0,0], add_labels=False, add_colorbar=False)\n",
    "sim2.elevation.plot(ax=axs[0,1], add_labels=False, add_colorbar=False)\n",
    "sim3.elevation.plot(ax=axs[1,0], add_labels=False, add_colorbar=False)\n",
    "im = sim4.elevation.plot(ax=axs[1,1], add_labels=False, add_colorbar=False)\n",
    "\n",
    "axs[0,0].set_title('dt = 500 yrs', fontsize=10, fontweight=\"bold\")\n",
    "axs[0,1].set_title('dt = 1,250 yrs', fontsize=10, fontweight=\"bold\")\n",
    "axs[1,0].set_title('dt = 2,500 yrs', fontsize=10, fontweight=\"bold\")\n",
    "axs[1,1].set_title('dt = 5,000 yrs', fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.2, -0.02, 0.6, 0.02]) \n",
    "cbar = fig.colorbar(im, cax=cbar_ax, extend='both', orientation='horizontal')\n",
    "cbar.set_label('Elevation (m)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxelev = np.zeros(4)\n",
    "maxelev[0] = sim1.elevation.max().data+0.\n",
    "maxelev[1] = sim2.elevation.max().data+0.\n",
    "maxelev[2] = sim3.elevation.max().data+0.\n",
    "maxelev[3] = sim4.elevation.max().data+0.\n",
    "\n",
    "print('Average max. elevation between the different simulation: %0.2f m'%maxelev.mean())\n",
    "print('Standard deviation: %0.2f m'%maxelev.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting mean elevation through time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'results/'\n",
    "def get_mean_elevation(ncout, maxtsp):\n",
    "    mean_z = []\n",
    "    for k in range(maxtsp+1):\n",
    "        ds = xr.open_dataset(ncout+str(k)+\".nc\")\n",
    "        mean_z.append(ds.elevation.mean().data+0.)\n",
    "    return mean_z\n",
    "\n",
    "mean1 = get_mean_elevation(os.path.join(out_path, \"500yr_stp\"), 40)\n",
    "mean2 = get_mean_elevation(os.path.join(out_path, \"1.25ky_stp\"), 40)\n",
    "mean3 = get_mean_elevation(os.path.join(out_path, \"2.5ky_stp\"), 40)\n",
    "mean4 = get_mean_elevation(os.path.join(out_path, \"5ky_stp\"), 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = np.arange(41)*2.5e3\n",
    "time2 = np.arange(21)*5.e3\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(4.5,6))\n",
    "plt.plot(time1/1000, mean1, label='dt = 0.5 ky', marker='^', lw=2)\n",
    "plt.plot(time1/1000, mean2, label='dt = 1.25 ky', marker='X', lw=2)\n",
    "plt.plot(time1/1000, mean3, label='dt = 2.5 ky', marker='o', lw=2)\n",
    "plt.plot(time2/1000, mean4, label='dt = 5 ky', marker='v', lw=2)\n",
    "\n",
    "ax.legend(loc=4, frameon=False, fontsize=8, prop={'weight':'bold'})\n",
    "plt.xlabel(\"Simulation time (ky)\", fontsize=10, fontweight=\"bold\")\n",
    "plt.ylabel(\"Mean elevation (m)\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "plt.axis([-2, 102, 95, 185])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The solutions for the mean landscape elevation show that the landscape reaches steady state in all cases, and overall the final elevations are in good agreement with a maximum elevation of 463±13 m.** \n",
    "\n",
    "Yet as the time step increases the differences between models increase over time. By the end of the simulation, the mean elevation difference between the case with Δt equals 500 years and the one at 5,000 years is around 6.5 %, whereas the difference with a Δt of 1250 years is below 1 %. It illustrates the transient nature of the landscape and its strong dependence on antecedent morphologies. Even small changes in elevation could potentially trigger completely different landscape features. \n",
    "\n",
    "> Compared to the explicit algorithm, the approach here relies on an implicit schema and produces a more stable solution for longer timescales. Yet time step limitations are still required to ensure a good representation of landscape features (e.g. knickpoint propagation) and care should be taken when choosing a given simulation time step.\n",
    "\n",
    "The iterative linear solvers of the implicit methods for both flow accumulation and erosion use previous time step solution as an initial guess. In cases in which the landscape does not change significantly between consecutive time steps, both the flow accumulation and erosion rates are likely to remain almost unchanged and the number of iterations required by the solver to reach convergence will be small. As an example, if the drainage network remains the same between two iterations, the flow accumulation solver solution will be obtained immediately and the results given directly. It highlights a second implication of the choice of time step. Not only does the time step influence the final landscape morphology, but it also controls the model running time. In some cases, similar running times will be achieved with smaller time steps if solver solutions are obtained in a reduced number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gospl-run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
